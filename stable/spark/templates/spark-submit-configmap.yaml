apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-submit
  labels:
    app: {{ template "spark.name" . }}
    chart: {{ template "spark.chart" . }}
    release: {{ .Release.Name }}
    heritage: {{ .Release.Service }}
data:
{{ include "v3io-configs.java.configMap" . | indent 2 }}

  spark-job-init.sh: |
    #!/usr/bin/env bash
    set -e

{{ include "v3io-configs.script.lookupService" . | indent 4 }}

    echo 'spark.master=spark://{{ template "spark.master-name" . }}:{{ .Values.master.servicePort }}' >> ${SPARK_HOME}/conf/spark-defaults.conf
    echo spark.driver.host=$(hostname -i) >> ${SPARK_HOME}/conf/spark-defaults.conf
    echo spark.executor.cores={{ .Values.submit.executorCores }} >> ${SPARK_HOME}/conf/spark-defaults.conf
    echo spark.executor.memory={{ .Values.submit.executorMemory }} >> ${SPARK_HOME}/conf/spark-defaults.conf
    echo spark.cores.max={{ .Values.submit.maxApplicationCores }} >> ${SPARK_HOME}/conf/spark-defaults.conf
    echo spark.sql.catalogImplementation=in-memory >> ${SPARK_HOME}/conf/spark-defaults.conf
    for arg in V3IO_USERNAME V3IO_PASSWORD V3IO_TENANT V3IO_ACCESS_KEY; do
      if [ "${!arg}" != "" ]; then
        echo spark.executorEnv.${arg}=${!arg} >> ${SPARK_HOME}/conf/spark-defaults.conf
      fi
    done
